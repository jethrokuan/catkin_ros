#+TITLE: My Catkin Workspacce

This catkin workspace is organized like a mono-repo, and will be used for all robotics projects.

The workspace is organized as follows:

- algorithms :: contains packages that process data and produce output. Typically, these packages use traditional techniques, or wrap neural networks that consume sensor data and output predictions.
- robots :: contains packages relevant to supporting the robots we have in the lab (e.g. the Franka Emika Panda)
- sensors ::  contains packages for sensor support (e.g. RGBD cameras, tactile sensors)
- utils :: contains any utilities that may be used throughout other packages
- systems :: for a particular experimental setup, a certain system might be use a different combination of sensors, robots and algorithms. Each system will be a catkin package that depends on packages, and contain system-specific code.

  Packages should be written targeting Python 3, and newer versions of ROS (Noetic and above).

* Initial Setup

#+BEGIN_SRC bash
cd ~
git clone https://github.com/jethrokuan/catkin_ros/ --recursive
cd src/robots/libfranka
mkdir build
cd build
cmake -DCMAKE_BUILD_TYPE=Release ..
cmake --build .
cd ~/catkin_ros/
rosdep install --from-paths src --ignore-src src -r -y --skip-keys libfranka
catkin_make_isolated -DCMAKE_BUILD_TYPE=Release -DFranka_DIR:PATH=~/catkin_ros/src/robots/libfranka/build
#+END_SRC

* Future Tasks
** TODO Update MoveIt! to latest (Melodic/Noetic/ROS 2)

Current MoveIt installed in Kinetic is missing some planners that the new ~panda_moveit_config~ uses.

** TODO Move to colcon build system

** TODO Add Training and offline evaluation of GGCNN

* Reference Documentation
** TF

In Rviz, the axes colors are as follows:

- X axis :: red
- Y axis :: green
- Z axis :: blue

** Cameras
*** Frames

The ~camera_link~ frame is a center point for all other link frames to relate to. In the D400 series, this is defined as the ~camera_depth_frame~. To verify, we can run:

#+BEGIN_SRC bash
rosrun tf tf_echo camera_depth_frame camera_link
#+END_SRC

We should see:

#+BEGIN_SRC text
At time 0.000
- Translation: [0.000, 0.000, 0.000]
- Rotation: in Quaternion [0.000, 0.000, 0.000, 1.000]
            in RPY (radian) [0.000, -0.000, 0.000]
            in RPY (degree) [0.000, -0.000, 0.000]
#+END_SRC

Image data is usually published in the optical frame of the camera. In practice, this means that to obtain camera data in another base frame,
*** Realsense
**** Camera Calibration

*** Image Processing
[[https://wiki.ros.org/depth_image_proc][depth_image_proc]] is a library that processes depth images produced by cameras such as the [[Realsense]].

~depth_image_proc/convert_metric~ converts raw uint16 images in mm to float depth image in m.

** AprilTag

[[https://april.eecs.umich.edu/software/apriltag][AprilTag]] is a visual fiducial system that is useful for multiple robotics tasks, including camera calibration. It uses simple printed targets that look like QR codes. The [[http://wiki.ros.org/apriltag_ros][AprilTag ROS]] library is able to establish the tf transform betwen the tag and the camera.

#+BEGIN_SRC bash
rosrun apriltag_ros continuous_detection.launch
#+END_SRC

To establish a transform between a camera and a base frame (e.g. a robot), we place the april tag at a known displacement (and rotation) from the robot frame. To publish a static transfrom, we use:

#+BEGIN_SRC bash
rosrun tf static_tf_publisher ...
#+END_SRC

We use the AprilTag to compute the transform from the camera to the tag.

We can then do:

#+BEGIN_SRC bash
rosrun tf tf_echo camera_link robot_frame
#+END_SRC

And save this transform for later use.
