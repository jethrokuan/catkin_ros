* Generative Grasping (ggrasp)

This repo contains two models:

** Generative Grasping CNN (GGCNN)

/Original README at [[https://github.com/dougsm/ggcnn]]/

GG-CNN is a lightweight, fully-convolutional network which predicts the quality
and pose of antipodal grasps at every pixel in an input depth image. The
lightweight and single-pass generative nature of GG-CNN allows for fast
execution and closed-loop control, enabling accurate grasping in dynamic
environments when objects are moved during the grasp attempt.

** GR-ConvNet

/Original README at https://github.com/skumra/robotic-grasping/

GR-ConvNet is a novel generative residual convolutional neural network based
model architecture which detects objects in the cameraâ€™s field of view and
predicts a suitable antipodal grasp configuration for the objects in the image.

* Obtaining the Training Data

GG-CNN can be trained on the Cornell Grasping dataset, and the Jacquard dataset.
